{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "ff66aa0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /home/user/news/lib/python3.8/site-packages (1.19.5)\n",
      "Requirement already satisfied: pandas in /home/user/news/lib/python3.8/site-packages (1.3.1)\n",
      "Requirement already satisfied: sklearn in /home/user/news/lib/python3.8/site-packages (0.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /home/user/news/lib/python3.8/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /home/user/news/lib/python3.8/site-packages (from pandas) (2021.1)\n",
      "Requirement already satisfied: scikit-learn in /home/user/news/lib/python3.8/site-packages (from sklearn) (0.24.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/user/news/lib/python3.8/site-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/user/news/lib/python3.8/site-packages (from scikit-learn->sklearn) (1.0.1)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /home/user/news/lib/python3.8/site-packages (from scikit-learn->sklearn) (1.7.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/user/news/lib/python3.8/site-packages (from scikit-learn->sklearn) (2.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install numpy pandas sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "8a24b89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "864fc6da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>The CDC currently reports 99031 deaths. In gen...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>States reported 1121 deaths a small rise from ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Politically Correct Woman (Almost) Uses Pandem...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>#IndiaFightsCorona: We have 1524 #COVID testin...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Populous states can generate large case counts...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0                                                  1  2\n",
       "0  1  The CDC currently reports 99031 deaths. In gen...  0\n",
       "1  2  States reported 1121 deaths a small rise from ...  0\n",
       "2  3  Politically Correct Woman (Almost) Uses Pandem...  1\n",
       "3  4  #IndiaFightsCorona: We have 1524 #COVID testin...  0\n",
       "4  5  Populous states can generate large case counts...  0"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Read the data\n",
    "df=pd.read_csv('Constraint_Train.csv', header=None, skiprows=1, encoding='utf-8')\n",
    "#Get shape and head\n",
    "df[2] = df[2].replace(['fake', 'real'], [1, 0])\n",
    "df[1] = df[1].replace('\\n', '', regex=True).str.strip()\n",
    "df.shape\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "d498910f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    1\n",
       "3    0\n",
       "4    0\n",
       "Name: 2, dtype: int64"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#DataFlair - Get the labels\n",
    "labels=df[2]\n",
    "labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "0d860064",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Chinese converting to Islam after realising th...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>11 out of 13 people (from the Diamond Princess...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>COVID-19 Is Caused By A Bacterium, Not Virus A...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Mike Pence in RNC speech praises Donald Trump’...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>6/10 Sky's @EdConwaySky explains the latest #C...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0                                                  1  2\n",
       "0  1  Chinese converting to Islam after realising th...  1\n",
       "1  2  11 out of 13 people (from the Diamond Princess...  1\n",
       "2  3  COVID-19 Is Caused By A Bacterium, Not Virus A...  1\n",
       "3  4  Mike Pence in RNC speech praises Donald Trump’...  1\n",
       "4  5  6/10 Sky's @EdConwaySky explains the latest #C...  0"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# #DataFlair - Split the dataset\n",
    "# x_train,x_test,y_train,y_test=train_test_split(df['tweet'], labels, test_size=0.2, random_state=7)\n",
    "# print(type(x_test))\n",
    "#Read the data\n",
    "df1=pd.read_csv('Constraint_Test.csv', header=None, skiprows=1, encoding='utf-8')\n",
    "df1[2] = df1[2].replace(['fake', 'real'], [1, 0])\n",
    "df1[1] = df1[1].replace('\\n', '', regex=True).str.strip()\n",
    "#Get shape and head\n",
    "df1.shape\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "dadce249",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    1\n",
       "2    1\n",
       "3    1\n",
       "4    0\n",
       "Name: 2, dtype: int64"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels1=df1[2]\n",
    "labels1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "bc52c766",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('X_train shape:', (6420,))\n",
      "('X_test shape:', (2140,))\n",
      "('y_train shape:', (6420,))\n",
      "('y_test shape:', (2140,))\n"
     ]
    }
   ],
   "source": [
    "x_train=df[1]\n",
    "y_train=labels\n",
    "x_test=df1[1]\n",
    "y_test=labels1\n",
    "print(('X_train shape:', x_train.shape))\n",
    "print(('X_test shape:', x_test.shape))\n",
    "print(('y_train shape:', y_train.shape))\n",
    "print(('y_test shape:', y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "7daa2c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=x_test\n",
    "output=y_test\n",
    "\n",
    "#DataFlair - Initialize a TfidfVectorizer\n",
    "tfidf_vectorizer=TfidfVectorizer(stop_words='english', max_df=0.7)\n",
    "\n",
    "#DataFlair - Fit and transform train set, transform test set\n",
    "tfidf_train=tfidf_vectorizer.fit_transform(x_train) \n",
    "tfidf_test=tfidf_vectorizer.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "e2fb5ee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 93.88%\n"
     ]
    }
   ],
   "source": [
    "#DataFlair - Initialize a PassiveAggressiveClassifier\n",
    "pac=PassiveAggressiveClassifier(max_iter=50)\n",
    "pac.fit(tfidf_train,y_train)\n",
    "\n",
    "#DataFlair - Predict on the test set and calculate accuracy\n",
    "y_pred=pac.predict(tfidf_test)\n",
    "score=accuracy_score(y_test,y_pred)\n",
    "print(f'Accuracy: {round(score*100,2)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "246cb09a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1064,   56],\n",
       "       [  75,  945]])"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#DataFlair - Build confusion matrix\n",
    "confusion_matrix(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "467e4010",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.engine.sequential.Sequential object at 0x7fe63e9f81f0>\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "model1 = tf.keras.models.load_model('model.h5')\n",
    "print(model1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "8b4bb445",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_15701/2326657970.py:6: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  x_train1 = x_train.str.replace('\\d+', '') # removing all numbers\n",
      "/tmp/ipykernel_15701/2326657970.py:9: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  x_test1 = x_test.str.replace('\\d+', '')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('X_train shape:', (6420, 100))\n",
      "('X_test shape:', (2140, 100))\n",
      "('y_train shape:', (6420,))\n",
      "('y_test shape:', (2140,))\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.python.keras.preprocessing.sequence import pad_sequences\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "x_train1 = x_train.str.replace('\\d+', '') # removing all numbers\n",
    "\n",
    "    \n",
    "x_test1 = x_test.str.replace('\\d+', '')\n",
    "\n",
    "    \n",
    "\n",
    "stop = stopwords.words('english')\n",
    "    \n",
    "x_train1 = x_train1.apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))\n",
    "\n",
    "    \n",
    "x_test1 = x_test1.apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))\n",
    "\n",
    "    \n",
    "tokenizer = Tokenizer(num_words=8656) #adding this parameter can  responsible for setting the size of the vocabulary i.e the most common num_words\n",
    "tokenizer.fit_on_texts(x_train1)\n",
    "    \n",
    "vocab_size = len(tokenizer.word_index) + 1  \n",
    "data = []\n",
    "punc = '.'\n",
    "for i in x_train1:\n",
    "    i = i[:-1]\n",
    "    token = word_tokenize(i)\n",
    "    if punc in token:\n",
    "        for index ,val in enumerate(token):\n",
    "            if punc == val:\n",
    "                token.pop(index)         \n",
    "    data.append(token)\n",
    "\n",
    "x_train1 = tokenizer.texts_to_sequences(data) \n",
    "x_test1 = tokenizer.texts_to_sequences(x_test1)\n",
    "    \n",
    "maxlen = 100\n",
    "x_train1 = pad_sequences(x_train1, padding='post', maxlen=maxlen)\n",
    "x_test1 = pad_sequences(x_test1, padding='post', maxlen=maxlen)\n",
    "\n",
    "y_train1 = y_train\n",
    "y_test1 = y_test\n",
    "# y_train1 = np.array(y_train)\n",
    "# y_test1 = np.array(y_test)\n",
    "    \n",
    "\n",
    "    \n",
    "# y_train1 = y_train1.astype('float64')\n",
    "# y_test1 = y_test1.astype('float64')\n",
    "    \n",
    "print(('X_train shape:', x_train1.shape))\n",
    "print(('X_test shape:', x_test1.shape))\n",
    "print(('y_train shape:', y_train1.shape))\n",
    "print(('y_test shape:', y_test1.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "402e7037",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=model1.predict(x_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "5f825ad7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.9321961 ]\n",
      " [0.26409903]\n",
      " [0.42257556]\n",
      " ...\n",
      " [0.03615418]\n",
      " [0.05544975]\n",
      " [0.55361444]]\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "02e7af9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y1=model1.predict(x_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "2787e62d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.07598627]\n",
      " [0.70487267]\n",
      " [0.05194101]\n",
      " ...\n",
      " [0.02632311]\n",
      " [0.04614675]\n",
      " [0.42349628]]\n"
     ]
    }
   ],
   "source": [
    "print(y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "6b88d2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pd.DataFrame(y)\n",
    "#print(y)\n",
    "y1 = pd.DataFrame(y1)\n",
    "#print(y)\n",
    "x_train2= pd.concat([pd.DataFrame(tfidf_train.todense()), y], axis=1)\n",
    "x_test2= pd.concat([pd.DataFrame(tfidf_test.todense()), y1], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "d58325f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0      1      2      3      4      5      6      7      8      9      \\\n",
      "0       0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
      "1       0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
      "2       0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
      "3       0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
      "4       0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
      "...     ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
      "6415    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
      "6416    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
      "6417    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
      "6418    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
      "6419    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
      "\n",
      "      ...  18170  18171  18172  18173  18174  18175  18176  18177  18178  \\\n",
      "0     ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
      "1     ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
      "2     ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
      "3     ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
      "4     ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
      "...   ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
      "6415  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
      "6416  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
      "6417  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
      "6418  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
      "6419  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
      "\n",
      "         0      \n",
      "0     0.932196  \n",
      "1     0.264099  \n",
      "2     0.422576  \n",
      "3     0.280695  \n",
      "4     0.099863  \n",
      "...        ...  \n",
      "6415  0.051312  \n",
      "6416  0.029882  \n",
      "6417  0.036154  \n",
      "6418  0.055450  \n",
      "6419  0.553614  \n",
      "\n",
      "[6420 rows x 18180 columns]\n"
     ]
    }
   ],
   "source": [
    "print(x_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "2749232d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import sparse\n",
    "y = sparse.csr_matrix(y) \n",
    "y1 = sparse.csr_matrix(y1) \n",
    "x_train2 = sparse.hstack((tfidf_train,y)) \n",
    "x_test2 = sparse.hstack((tfidf_test,y1)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "d48786f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 93.79%\n"
     ]
    }
   ],
   "source": [
    "#DataFlair - Predict on the test set and calculate accuracy\n",
    "pac=PassiveAggressiveClassifier(max_iter=50)\n",
    "pac.fit(x_train2,y_train)\n",
    "y_pred=pac.predict(x_test2)\n",
    "score=accuracy_score(y_test,y_pred)\n",
    "print(f'Accuracy: {round(score*100,2)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "690e5fdd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "local-venv",
   "language": "python",
   "name": "local-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
